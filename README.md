# Multi-modal  fusion for  object detection

Provide a summary of Multi-modal  fusion for  object detection <br> 
(**Paper, Code, Dataset and more**). 

--------------------------------------------------------------------------------------
## Content:

1. <a href="#Multi-modal  fusion for  object detection Dataset"> Multi-modal  fusion for  object detection Dataset </a>
2. <a href="#Multi-modal  fusion for  object detection（RGB-T)"> Multi-modal  fusion for  object detection（RGB-T) </a>
3. <a href="#Multi-modal  fusion for  object detection(RGB-D)"> Multi-modal  fusion for  object detection（RGB-D)</a>
4. <a href="#Multi-modal  fusion for  object detection(RGB-Lidar)"> Multi-modal  fusion for  object detection（RGB-Lidar)</a>
5. <a href="#Multi-modal  fusion for  object detection(others)"> Multi-modal  fusion for  object detection（others)</a>
--------------------------------------------------------------------------------------
# Multi-modal  fusion for  object detectiont Dataset <a id="Dataset" class="anchor" href="Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a> 
--------------------------------------------------------------------------------------
## RGB-T:
**DroneVehicle（2020）**  <br>
DroneVehicle dataset consists of a total of 56878 image sets, half of which are RGB images and the rest are Thermal images.  <br>
You can find in [Paper](https://arxiv.xilesou.top/pdf/2003.02437.pdf)   <br>
**UAV RGB-T 2400**  <br>
UAV-based dataset (UVA RGB-T 2400) with unregistered visible light and thermal infrared image pairs.  <br>
You can find in [Paper](https://ieeexplore.ieee.org/document/10315195)   <br>

**VT821（2018）**  <br>
VT821 includes 821 RGB-T image pairs and their ground truth annotations for the saliency detection purpose.  <br>
You can find in [Paper](https://github.com/mmic-lcl/Datasets-and-benchmark-code)  <br>
**VT1000（2019）**  <br>
VT1000 contains 1000 pairs of RGB-T images including more than 400 kinds of common objects collected in 10 types of scenes under different illumination conditions. <br>
You can find in [Paper](https://github.com/mmic-lcl/Datasets-and-benchmark-code)   <br>
**VT5000（2020）**  <br>
ncludes 5000 spatially aligned RGBT image pairs with ground truth annotations. VT5000 has 11 challenges collected in different scenes and environments for exploring the robustness of algorithms.<br>
You can find in [Paper](https://paperswithcode.com/dataset/vt5000)   <br>
**RoadScene（2020)**  <br>
it contains a total of 221 sets of aligned RGB-T image pairs. The main scenarios in the dataset are roads, including vehicles, pedestrians, traffic signs, and other objects. <br>
You can find in [Paper](https://github.com/hanna-xu/RoadScene)   <br>


## RGB-D:
**NJUD（2014）**  <br>
NJUD is a large RGB-D dataset containing 1,985 image pairs. The stereo images were collected from the Internet and 3D movies, while photographs were taken by a Fuji W3 camera. 
<br>You can find in [Paper](https://paperswithcode.com/dataset/nju2k)   <br>
**NLPR**  <br>
 NLPR contains 1000 pairs of RGB and depth images, covering rich indoor and outdoor scenes.<br>
You can find in [Paper](https://pan.baidu.com/s/1pocKI_KEvqWgsB16pzO6Yw)  <br>
**SIP（2020)**  <br>
The Salient Person dataset (SIP) contains 929 salient person samples with different poses and illumination conditions.<br>
**SSD**  <br>
It includes 80 samples covering indoor and outdoor scenes.<br>
You can find in [Paper](https://pan.baidu.com/s/1zNL9-KSQwGILdAAfStMXWQ).<br>
**ReDWeb-S**  <br>
 ReDWeb-S is a large-scale challenging dataset for Salient Object Detection. It has totally 3179 images with various real-world scenes and high-quality depth maps. The dataset is split into a training set with 2179 RGB-D image pairs and a testing set with the remaining 1000 image pairs. <br>
You can find in [Paper](https://paperswithcode.com/dataset/redweb-s)   <br>
**COME15K**  <br>
COME15K is an RGB-D saliency detection dataset which contains 15,625 image pairs with high quality polygon-/scribble-/object-/instance-/rank-level annotations.<br>
You can find in [Paper](https://paperswithcode.com/dataset/come15k)   <br>
**RGBD135**  <br>
It Contains 135 images captured by Microsoft Kinect.<br>
You can find in [Paper](https://aistudio.baidu.com/datasetdetail/155597)   <br>
**LFSD**  <br>
The Light Field Saliency Database (LFSD) contains 100 light fields with 360×360 spatial resolution. A rough focal stack and an all-focus image are provided for each light field. The images in this dataset usually have one salient foreground object and a background with good color contrast.<br>
You can find in [Paper](https://paperswithcode.com/dataset/lfsd)   <br>
**SUN-RGBD**
It contains 10335 real RGB-D images of room scenes. Each RGB image has a corresponding depth and segmentation map. As many as 700 object categories are labeled. The training and testing sets contain 5285 and 5050 images, respectively. <br>
You can find in [Paper](https://paperswithcode.com/dataset/sun-rgb-d)   <br>

## RGB-Lidar:
**KITTI**  <br>
The entire dataset of KITTI was collected in Karlsruhe, Germany, and can be divided into five categories according to the scene: "road", "city", "residential area", "campus" and "pedestrian". <br>
You can find in [Paper](http://www.cs.toronto.edu/~urtasun/publications/geiger_et_al_ijrr13.pdf)   <br>
**nuScenes**  <br>
It collected 1000 driving scenes in Boston and Singapore, two cities that are known for their dense traffic and highly challenging driving situations.<br>
You can find in [Paper](https://arxiv.org/pdf/1903.11027.pdf)   <br>
**nuScenes-lidarseg**  <br>
It is the most complete test dataset for LiDAR, including 850 training scenarios, 150 test scenarios, an astonishing 1.4 billion annotation points, 40,000 point cloud frames, and 32 levels of classification. <br>
You can find in [Paper](https://www.nuscenes.org/nuscenes#panoptic)   <br>
**JRDB**  <br>
The dataset includes 64 minutes of annotated multimodal sensor data including stereo cylindrical 360 degrees RGB video at 15 fps, 3D point clouds from two Velodyne 16 Lidars, line 3D point clouds from two Sick Lidars, audio signal, RGB-D video at 30 fps, 360 degrees spherical image from a fisheye camera and encoder values from the robot's wheels. <br>
You can find in [Paper](https://blog.csdn.net/moxibingdao/article/details/106667809)   <br>










--------------------------------------------------------------------------------------
# Multi-modal  fusion for  object detection（RGB-T)
## 2023
**No.** | **Pub.** | **Title** | **Links** 
:-: | :-: | :-  | :-: 
01 | **IEEE** | Cross-Modality Double Bidirectional Interaction and Fusion Network for RGB-T Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10032588)/[Code]()
02 | **IEEE** | Feature Enhancement and Fusion for RGB-T Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10222404/)/[Code]()
03 | **IEEE** | Modality-Induced Transfer-Fusion Network for RGB-D and RGB-T Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/9925217)/[Code]()
04 | **IEEE** | SF-YOLO: RGB-T Fusion Object Detection in UAV Scenes| [Paper](https://ieeexplore.ieee.org/document/10270358)/[Code]()
05 | **IEEE** | CAVER: Cross-Modal View-Mixed Transformer for Bi-Modal Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10015667)/[Code]()
06| **IEEE** | Scribble-Supervised RGB-T Salient Object Detection | [Paper](https://ieeexplore.ieee.org/document/10219673)/[Code]()
07 | **IEEE** | (*)Modality Registration and Object Search Framework for UAV-Based Unregistered RGB-T Image Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10315195)/[Code]()
08 | **IEEE** | A Potential Vision-Based Measurements Technology: Information Flow Fusion Detection Method Using RGB-Thermal Infrared Images| [Paper](https://ieeexplore.ieee.org/document/10015881#full-text-header)/[Code]()
09 | **IEEE** | Vehicle Detection Based on Adaptive Multimodal Feature Fusion and Cross-Modal Vehicle Index Using RGB-T Images| [Paper](https://ieeexplore.ieee.org/document/10179923/)/[Code]()
10| **IEEE** | Does Thermal Really Always Matter for RGB-T Salient Object Detection? | [Paper](https://ieeexplore.ieee.org/document/9926193#full-text-header)/[Code]()
11 | **IEEE** | HRTransNet: HRFormer-Driven Two-Modality Salient Object Detection | [Paper](https://ieeexplore.ieee.org/document/9869666)/[Code]()
12 | **IEEE** | WaveNet: Wavelet Network With Knowledge Distillation for RGB-T Salient Object Detection | [Paper](https://ieeexplore.ieee.org/document/10127616)/[Code]()





# Multi-modal  fusion for  object detection（RGB-D)
## 2023
**No.** | **Pub.** | **Title** | **Links** 
:-: | :-: | :-  | :-: 
01 | **IEEE** | Modality-Induced Transfer-Fusion Network for RGB-D and RGB-T Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/9925217)/[Code]()
02 | **IEEE** | CAVER: Cross-Modal View-Mixed Transformer for Bi-Modal Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10015667)/[Code]()
03| **IEEE** |(survey) RGB-D and Thermal Sensor Fusion: A Systematic Literature Review| [Paper](https://ieeexplore.ieee.org/document/10201865)/[Code]()
04 | **IEEE** | CMCLNet Cross-Modality Attention Fusion and Cross-Level Feature Interaction for RGBD salient object detection| [Paper](https://ieeexplore.ieee.org/document/10262928)/[Code]()
05 | **IEEE** | Depth Injection Framework for RGBD Salient Object Detection| [Paper](https://ieeexplore.ieee.org/document/10258039#full-text-header)/[Code]()
# Multi-modal  fusion for  object detection（RGB-Lidar)
## 2023
**No.** | **Pub.** | **Title** | **Links** 
:-: | :-: | :-  | :-: 
01| **IEEE** | ImLiDAR: Cross-Sensor Dynamic Message Propagation Network for 3-D Object Detection| [Paper](https://ieeexplore.ieee.org/document/10268462)/[Code]()
02 | **IEEE** | EPNet++: Cascade Bi-Directional Fusion for Multi-Modal 3D Object Detection| [Paper](https://ieeexplore.ieee.org/document/9983516)/[Code]()
# Multi-modal  fusion for  object detection（others)
## 2023
**No.** | **Pub.** | **Title** | **Links** |**Remark**|
:-: | :-: | :-  | :-: | :-: |
01| **IEEE** |Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and 3D Localization | [Paper]()/[Code]()|RGB-D-Lidar|

--------------------------------------------------------------------------------------
# keep updating
